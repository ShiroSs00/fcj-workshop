---
title: "Event 1"
date: "`r Sys.Date()`"
weight: 1
chapter: false
pre: " <b> 4.1. </b> "
---

# Summary Report: “​AI/ML/GenAI on AWS”

# Summary Report: "AI/ML/GenAI on AWS"

### Event Information

- **Date**: Saturday, November 15, 2025
- **Time**: 8:30 AM – 12:00 PM
- **Location**: AWS Vietnam Office

### Event Objectives

- Introduce AWS AI/ML services landscape in Vietnam
- Provide hands-on knowledge on Amazon SageMaker for end-to-end ML workflows
- Explore Generative AI capabilities with Amazon Bedrock
- Share best practices in prompt engineering and Retrieval-Augmented Generation (RAG)
- Demonstrate building production-ready AI applications

### Event Agenda

#### 8:30 – 9:00 AM | Welcome & Introduction

- Participant registration and networking
- Workshop overview and learning objectives
- Ice-breaker activity
- Overview of the AI/ML landscape in Vietnam

#### 9:00 – 10:30 AM | AWS AI/ML Services Overview

- **Amazon SageMaker** – End-to-end ML platform
  - Data preparation and labeling
  - Model training, tuning, and deployment
  - Integrated MLOps capabilities
- **Live Demo**: SageMaker Studio walkthrough

#### 10:30 – 10:45 AM | Coffee Break

#### 10:45 AM – 12:00 PM | Generative AI with Amazon Bedrock

- **Foundation Models**: Claude, Llama, Titan – comparison & selection guide
- **Prompt Engineering**: Techniques, Chain-of-Thought reasoning, Few-shot learning
- **Retrieval-Augmented Generation (RAG)**: Architecture & Knowledge Base integration
- **Bedrock Agents**: Multi-step workflows and tool integrations
- **Guardrails**: Safety and content filtering
- **Live Demo**: Building a Generative AI chatbot using Bedrock

### Key Highlights

#### Amazon SageMaker: End-to-End ML Platform

- **Fully managed service** for building, training, and deploying machine learning models
- **Data preparation**: Automated data labeling and preprocessing
- **Model training**: Hyperparameter tuning, distributed training
- **MLOps integration**: Model monitoring, versioning, and continuous deployment
- **SageMaker Studio**: Unified IDE for data scientists and ML engineers

#### Foundation Models & Model Selection

- **Claude**: Advanced reasoning, long-context understanding, instruction-following
- **Llama**: Open-source efficiency, customization capabilities
- **Titan**: AWS-optimized models for specific use cases
- **Selection criteria**: Task type, latency requirements, cost considerations

#### Prompt Engineering Techniques

- **Chain-of-Thought (CoT)**: Break complex problems into step-by-step reasoning
- **Few-shot learning**: Provide examples to guide model behavior
- **Zero-shot prompting**: Direct instructions without examples
- **Temperature and parameters**: Fine-tuning model output characteristics

#### Retrieval-Augmented Generation (RAG)

- **Architecture**: Query → Retrieval → Context → Generation
- **Knowledge Base integration**: Connect to enterprise data sources
- **Semantic search**: Finding relevant context from large datasets
- **Reducing hallucinations**: Grounding responses in actual data

#### Bedrock Agents & Automation

- **Multi-step workflows**: Orchestrating complex AI-driven tasks
- **Tool integration**: Connecting to APIs, databases, and external services
- **Autonomous decision-making**: Agents executing tasks without human intervention
- **Enterprise workflow automation**: Improving efficiency and reducing manual work

#### Safety & Guardrails

- **Content filtering**: Preventing harmful or inappropriate outputs
- **PII protection**: Masking sensitive information
- **Compliance**: Meeting regulatory requirements
- **Custom policies**: Organization-specific safety rules

### Key Takeaways

#### Technical Insights

- **SageMaker ecosystem**: Comprehensive solution for entire ML lifecycle
- **Foundation Models**: Leverage pre-trained models for faster time-to-value
- **RAG pattern**: Combine generative AI with retrieval for accurate, contextual responses
- **Bedrock Agents**: Build intelligent automation without extensive AI expertise

#### Best Practices

- **Phased approach**: Start with simple use cases before complex automation
- **Prompt optimization**: Invest time in prompt engineering for better results
- **Data quality**: Foundation for successful ML and AI applications
- **Safety first**: Implement guardrails and monitoring from the start

#### Business Impact

- **Accelerated development**: Pre-built models reduce time-to-market
- **Cost efficiency**: Pay-per-token pricing with managed services
- **Scalability**: AWS infrastructure handles varying loads automatically
- **Innovation**: Enable new use cases previously not feasible

### Applying to Work

- **Implement SageMaker**: Evaluate current ML pipelines for migration opportunities
- **Adopt Bedrock**: Pilot generative AI features in existing applications
- **RAG implementation**: Build knowledge-aware AI systems for business use cases
- **Prompt engineering**: Develop prompt templates and best practices for the team
- **Bedrock Agents**: Automate routine workflows using multi-step AI agents
- **Safety measures**: Establish guardrails and monitoring for production deployments

### Event Experience

Attending the **"AI/ML/GenAI on AWS"** workshop provided invaluable exposure to cutting-edge AI technologies and practical implementation strategies.

#### Learning from AWS experts

- Gained comprehensive understanding of AWS AI/ML service portfolio
- Learned real-world best practices for deploying generative AI in production
- Understood the strengths and trade-offs of different foundation models

#### Hands-on technical exposure

- **SageMaker Studio demo** showed the complete ML development workflow
- **Bedrock chatbot demo** demonstrated rapid prototyping of generative AI applications
- Learned practical prompt engineering techniques for better AI output
- Understood RAG architecture for building accurate, context-aware AI systems

#### Key insights gained

- Foundation models are accessible and cost-effective for enterprise use
- Prompt engineering is a critical skill for maximizing AI system performance
- RAG pattern solves hallucination problems by grounding responses in data
- Bedrock Agents can automate complex multi-step business processes

#### Practical applications

- Can implement SageMaker for data-driven ML projects
- Bedrock can accelerate development of AI-powered features
- RAG patterns apply to knowledge management and Q&A systems
- Guardrails ensure responsible AI deployment

#### Networking opportunities

- Connected with AWS specialists and fellow participants
- Discussed AI/ML challenges and solutions with peers
- Gained insights into Vietnam's growing AI/ML landscape

#### Lessons learned

- Start with pre-trained foundation models before building custom models
- Invest in prompt engineering for significant performance improvements
- Implement safety measures and monitoring from project inception
- Phased approach reduces risk and accelerates time-to-value

> Overall, the event not only provided technical knowledge but also helped me reshape my thinking about application design, system modernization, and cross-team collaboration.
